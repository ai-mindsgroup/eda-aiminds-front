# üîß Corre√ß√£o de Timeout no Upload de Arquivos

## üêõ Problema

**Erro**: `AxiosError: timeout of 30000ms exceeded`

**Situa√ß√£o**: Upload de arquivos CSV grandes excedia o timeout padr√£o de 30 segundos.

```json
{
    "message": "timeout of 30000ms exceeded",
    "code": "ECONNABORTED"
}
```

## üéØ Causa Raiz

1. **Timeout muito curto**: 30 segundos (30000ms) n√£o √© suficiente para:
   - Arquivos CSV com muitas linhas (>100k linhas)
   - Conex√µes lentas
   - Processamento intensivo no backend

2. **Falta de feedback**: Usu√°rio n√£o sabia o progresso do upload

3. **Mensagens de erro gen√©ricas**: N√£o explicava claramente o problema

## ‚úÖ Solu√ß√£o Implementada

### 1. **Aumentado Timeout Global** (`src/lib/axios.ts`)

```typescript
// ANTES:
timeout: 30000, // 30 segundos

// DEPOIS:
timeout: 120000, // 2 minutos
```

### 2. **Timeout Espec√≠fico para Upload** (`src/components/FileUploader.tsx`)

```typescript
const response = await axios.post<UploadResponse>('/csv/upload', formData, {
  headers: {
    'Content-Type': 'multipart/form-data',
  },
  timeout: 300000, // 5 minutos para arquivos CSV grandes
  onUploadProgress: (progressEvent) => {
    if (progressEvent.total) {
      const percentCompleted = Math.round((progressEvent.loaded * 100) / progressEvent.total);
      setUploadProgress(`Enviando para o servidor... ${percentCompleted}%`);
    }
  },
});
```

### 3. **Barra de Progresso Visual**

Agora o usu√°rio v√™:
- `"Enviando para o servidor... 25%"`
- `"Enviando para o servidor... 50%"`
- `"Enviando para o servidor... 100%"`

### 4. **Mensagens de Erro Aprimoradas**

```typescript
if (error.code === 'ECONNABORTED') {
  errorTitle = 'Tempo limite excedido';
  errorText = 'O arquivo √© muito grande ou o servidor est√° demorando muito. Tente um arquivo menor ou aguarde alguns minutos.';
} else if (error.code === 'ERR_NETWORK') {
  errorTitle = 'Erro de conex√£o';
  errorText = 'N√£o foi poss√≠vel conectar ao servidor. Verifique se o backend est√° rodando.';
}
```

## üìä Compara√ß√£o de Timeouts

| Opera√ß√£o | Antes | Depois | Justificativa |
|----------|-------|--------|---------------|
| Requisi√ß√µes gerais | 30s | 2min | APIs podem ser lentas |
| Upload de CSV | 30s | 5min | Arquivos grandes + processamento |
| Health check | 30s | 2s | Precisa ser r√°pido |

## üéØ Capacidade Estimada

Com os novos timeouts, o sistema suporta:

| Tamanho do Arquivo | Tempo Estimado | Status |
|-------------------|----------------|--------|
| < 1 MB | 1-5s | ‚úÖ R√°pido |
| 1-10 MB | 5-30s | ‚úÖ Normal |
| 10-50 MB | 30-120s | ‚úÖ OK |
| 50-200 MB | 2-5min | ‚ö†Ô∏è Lento mas funcional |
| > 200 MB | > 5min | ‚ùå Pode falhar |

## üí° Recomenda√ß√µes para o Backend

Para melhorar ainda mais o desempenho:

### 1. **Processamento Ass√≠ncrono**

```python
# Ao inv√©s de processar tudo no upload:
@app.post("/csv/upload")
async def upload_csv(file: UploadFile):
    # Salva o arquivo
    file_id = save_file(file)
    
    # Inicia processamento em background
    background_tasks.add_task(process_csv, file_id)
    
    # Retorna imediatamente
    return {"file_id": file_id, "status": "processing"}
```

### 2. **Streaming de Dados**

```python
# Processa linha por linha ao inv√©s de carregar tudo na mem√≥ria
import pandas as pd

for chunk in pd.read_csv(file, chunksize=10000):
    process_chunk(chunk)
```

### 3. **Compress√£o**

```python
# Aceita arquivos .csv.gz
import gzip

if file.filename.endswith('.gz'):
    with gzip.open(file.file) as f:
        df = pd.read_csv(f)
```

### 4. **Limite de Tamanho**

```python
from fastapi import File, UploadFile, HTTPException

MAX_FILE_SIZE = 100 * 1024 * 1024  # 100 MB

@app.post("/csv/upload")
async def upload_csv(file: UploadFile = File(...)):
    contents = await file.read()
    if len(contents) > MAX_FILE_SIZE:
        raise HTTPException(413, "File too large")
```

## üß™ Como Testar

### 1. **Arquivo Pequeno** (< 1 MB)
```bash
# Deve ser r√°pido (< 5s)
curl -X POST http://localhost:8000/csv/upload \
  -F "file=@small.csv"
```

### 2. **Arquivo M√©dio** (10 MB)
```bash
# Deve funcionar (< 30s)
curl -X POST http://localhost:8000/csv/upload \
  -F "file=@medium.csv"
```

### 3. **Arquivo Grande** (50 MB)
```bash
# Deve funcionar mas demorar (1-2min)
curl -X POST http://localhost:8000/csv/upload \
  -F "file=@large.csv"
```

## üîç Troubleshooting

### Ainda dando timeout?

**1. Verifique o tamanho do arquivo:**
```javascript
console.log('Tamanho do arquivo:', file.size / 1024 / 1024, 'MB');
```

**2. Verifique a velocidade da conex√£o:**
```bash
# Windows PowerShell
Test-Connection -ComputerName srv774816.hstgr.cloud -Count 4
```

**3. Aumente o timeout ainda mais:**
```typescript
// Em src/components/FileUploader.tsx
timeout: 600000, // 10 minutos
```

**4. Verifique logs do backend:**
- O backend pode estar travando no processamento
- Mem√≥ria insuficiente
- Processamento muito lento

### Backend est√° demorando muito?

**1. Perfil de performance:**
```python
import cProfile
cProfile.run('process_csv(file)')
```

**2. Monitore uso de recursos:**
```bash
# CPU e mem√≥ria
htop

# Disk I/O
iotop
```

**3. Otimize opera√ß√µes lentas:**
- Use `pandas` com `dtype` especificado
- Evite `.apply()` quando poss√≠vel
- Use opera√ß√µes vetorizadas

## üìö Refer√™ncias

- [Axios Timeout Configuration](https://axios-http.com/docs/req_config)
- [Handling Large Files in FastAPI](https://fastapi.tiangolo.com/tutorial/request-files/)
- [Pandas Performance](https://pandas.pydata.org/docs/user_guide/enhancingperf.html)

---

**Status**: ‚úÖ Corrigido
**Data**: 09/10/2025
**Vers√£o**: 1.0
